import logging
import chromadb
from chromadb import PersistentClient
import tiktoken
import os

# ×§×•× ×¤×™×’×•×¨×¦×™×™×ª ×”×œ×•×’×™× ×’ ×”×‘×¡×™×¡×™×ª
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# ×™×¦×™×¨×ª × ×ª×™×‘ ×§×‘×•×¢ ×œ-ChromaDB ×‘×ª×•×š ×ª×™×§×™×™×ª ×”×¤×¨×•×™×§×˜
CHROMA_PATH = os.path.join(os.path.dirname(__file__), "..", "chroma_db")
client = PersistentClient(path=CHROMA_PATH)

def get_chroma_collection(business_id):
    collection_name = f"biz_{business_id}"
    return client.get_or_create_collection(name=collection_name)

def retrieve_context_from_chroma(business_id, query, k=3):
    collection = get_chroma_collection(business_id)
    results = collection.query(query_texts=[query], n_results=k)
    return "\n".join(results["documents"][0]) if results["documents"] else ""

def split_text(text, max_tokens=200):
    enc = tiktoken.get_encoding("cl100k_base")
    words = text.split("\n")
    chunks, current_chunk = [], []
    current_len = 0

    for line in words:
        tokens = len(enc.encode(line))
        if current_len + tokens > max_tokens:
            chunks.append("\n".join(current_chunk))
            current_chunk = [line]
            current_len = tokens
        else:
            current_chunk.append(line)
            current_len += tokens

    if current_chunk:
        chunks.append("\n".join(current_chunk))

    return chunks

def load_business_knowledge(business_id, raw_text):
    if not raw_text.strip():
        logging.warning("âš ï¸ ××–×”×¨×”: ××™×Ÿ ×˜×§×¡×˜ ×œ×”×¢×œ×•×ª")
        return 0  # ××™×Ÿ ×ª×•×›×Ÿ ×œ×”×•×¡×™×£

    collection = get_chroma_collection(business_id)
    logging.info(f"ğŸš€ ××ª×—×™×œ×™× ×˜×¢×™× ×ª ×™×“×¢ ×œ×¢×¡×§ {business_id}...")

    try:
        results = collection.get()
        all_ids = results.get("ids", [])
        if all_ids:
            collection.delete(ids=all_ids)
            logging.info(f"ğŸ—‘ï¸ × ××—×§×• {len(all_ids)} ×¤×¨×™×˜×™× ×™×©× ×™× ××”×§×•×œ×§×©×Ÿ")
        else:
            logging.info("â„¹ï¸ ××™×Ÿ ×¤×¨×™×˜×™× ×™×©× ×™× ×œ××—×™×§×”")
    except Exception as e:
        logging.error(f"âš ï¸ ×©×’×™××” ×‘××—×™×§×ª ×ª×•×›×Ÿ ×™×©×Ÿ: {e}")

    chunks = split_text(raw_text)
    documents = [chunk for chunk in chunks if chunk.strip()]
    ids = [f"{business_id}_{i}" for i in range(len(documents))]

    try:
        collection.add(documents=documents, ids=ids)
        logging.info(f"âœ… × ×˜×¢× ×• {len(documents)} ×§×˜×¢×™× ×—×“×©×™× ×œÖ¾Chroma")
    except Exception as e:
        logging.error(f"âš ï¸ ×©×’×™××” ×‘×”×•×¡×¤×ª ×ª×•×›×Ÿ ×—×“×©: {e}")
        return 0

    return len(documents)
